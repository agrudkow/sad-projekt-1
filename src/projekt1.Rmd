---
title: "Projekt 1"
author: "Banzekulivakha Zhan, Grudkowski Artur"
date: "18 04 2021"
output: html_document
---

## Struktura projektu
Struktura katalogów w projekcie przedstawia się nastepująco:

* data - katalog przechowyjący dane
* info - katalog przechowujący pliki z treścią zadania
* renv - katalog odpowiedzialny ze wirtulane środowisko języka R
* src - katalog przechowujący kod żródłowy projektu i pliki wyjściowe
* inne pliki konfiguracjne

## Wyamgane biblioteki i konfiguracja pakeitu *knit*
> Poniżej linkwoane bibliteki są wymagane do poprawnej "kompilacji" notatnika, z tąd też wymagana jest ich wcześniejsza instalacja.

```{r setup, warning=FALSE, message=FALSE}
library(tidyverse)
library(rprojroot)

knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(echo = TRUE)
```

## Zadanie 1

### Przygotowanie danych
Sekcja ta definiuje funkcje odpowiedzilne za odpowiednie wczytanie danych i ich przygotowanie. 

* load_data - wczytuje dane z pliku do tabeli (data frame-u)
* prepare data:
  + zmienia nazwy kolumn - ma to na celu poprawić czytelność kodu
  + wydzielenie przedział czasu, którego dotyczny zadanie (druga połowa 2019) 

```{r}
load_data <- function(path) {
  return(read.table(path, sep = ",", header = TRUE))
}

prepare_data <- function(df) {
  # Change col names
  col_names <- c( "TICKER", "DATE", "OPEN", "HIGH", "LOW", "CLOSE", "VOL")
  colnames(df) <- col_names

  # Filter data to suit assagnment details (transactions in second half of 2019)
  df <- df[df$DATE >= 20190701 & df$DATE <= 20191231,]
  
  return(df[order(df$DATE),])
}
```

### Dla zadanych spółek1 notowanych na WGPW, na podstawie ich notowan z drugiej połowy roku 2019 (z pliku zad1mst.zip):

### (a) wyznacz procentowe zmiany cen zamkniecia tych spółek

Zmiany procentowe są interpretowane jako zmiany zamknięcia między dwoma następującymi notowaniami w dwóch kolejnych dniach.
Wynik dla notowania *i-1* i *i* jest liczny ze wzoru: $result = (n(i - 1) - n(i)/n(i)$, gdzie *n* oznacza zbiór notowań.

* calc_close_diff - zwraca zmian procentowe wyliczone na podstawie schematu przedstawionego powyżej

```{r}
calc_close_diff <- function(dataset) {
  # Init empty vector
  close_diff <- c()

  for(i in 2:nrow(dataset)) {
    first_day_val <- dataset$CLOSE[i - 1]
    second_day_val <- dataset$CLOSE[i]

    diff <- (first_day_val - second_day_val) / first_day_val
    # Convert to percentage
    diff <- diff * 100
    close_diff <- c(close_diff, diff)
  }

  return(close_diff)
}
```

#### Zmiany procentowe dla dla spółki PLAY
```{r}
# PLAY
close_diff_play <- load_data("./data/p1mst/PLAY.mst") %>% prepare_data %>% calc_close_diff

print(close_diff_play)
```

#### Zmiany procentowe dla dla spółki LPP
```{r}
# LPP
close_diff_lpp <- load_data("./data/p1mst/LPP.mst") %>% prepare_data %>% calc_close_diff

print(close_diff_lpp)
```

### (b) zilustruj rozkłady ww. zmian (histogramy + wykresy pudełkowe)

* draw_plots - generuje histogram i wykres pudełkowy dla zadanych danych zmiany cen zamkniecia spółek

```{r draw_plots}
draw_plots <- function(data) {
  hist(data, main="Histogram rozkładu procentowej zmiany cen zamknięcia", xlab="Zmiana procentowa", ylab="Liczność", col="darkmagenta", breaks=50)
  boxplot(data, main="Wykres pudełkowy rozkładu procentowej zmiany cen zamknięcia", xlab = "Zmiana procentowa", horizontal = TRUE)
  axis(side=1, at=seq(as.integer(min(data))-1,as.integer(max(data))+1, 1))
}

```

#### Wykres dla spółki PLAY
```{r}
draw_plots(close_diff_play)
```

#### Wykres dla spółi LPP
```{r}
draw_plots(close_diff_lpp)
```

### (c) wyestymuj parametry rozkładów normalnych mogacych modelowac ww. rozkłady

 * estimate_dnorm_params - zwraca listę zawierającą średnia i odchylenie standardowe wyliczone na podstawie danych wejściowych

```{r}
estimate_dnorm_params <- function(data) {
  return(list(mean=mean(data), sd=sd(data)))
}
```

#### Estymacja dla spółki PLAY
```{r}
dnorm_params_play <- estimate_dnorm_params(close_diff_play)

cat("Średnia: ", dnorm_params_play$mean)
cat("Odchylenie standardowe: ", dnorm_params_play$sd)
```

#### Estymacja dla spółki LPP
```{r}
dnorm_params_lpp <- estimate_dnorm_params(close_diff_lpp)

cat("Średnia: ", dnorm_params_lpp$mean)
cat("Odchylenie standardowe: ", dnorm_params_lpp$sd)
```

### (d) porównaj graficznie rozkłady modelowe z danymi
Porównanie zostało zrealizowanie poprzez połącznie wykresu uzykanego rozkładu normalnego wraz z histogramem (sekcja 1 b).

* plot_comparison - generuje wspomnien wyżej połącznie dwóch wykresów

```{r}
plot_comparison <- function(data, dnorm_params, col="darkmagenta") {
  hist <- hist(data, main="Porównanie rozkładu modelowego (normalnego) z danymi", xlab="Zmiana procentowa", ylab="Liczność", col=col, breaks=50) 
  axis(side=1, at=seq(as.integer(min(data)) - 1, as.integer(max(data)) + 1, 1))
  xfit <- seq(min(data), max(data), length = 40) 
  yfit <- dnorm(xfit, mean = dnorm_params$mean, sd = dnorm_params$sd) 
  yfit <- yfit * diff(hist$mids[1:2]) * length(data) 
  lines(xfit, yfit, col = "black", lwd = 2)
}
```

#### Porównanie dla spółki PLAY
```{r}
plot_comparison(close_diff_play, dnorm_params_play)
max(close_diff_play)
```

#### Porównanie dla spółki LPP
```{r}
plot_comparison(close_diff_lpp, dnorm_params_lpp)
```

#### Komentarz
Na podstawie wyżej wygenerowanych porównań jesteśy w stanie stwierdzić, iż estymacja przebiegła pomyślnie, poniewać charakterystyka estymowanych rozkładów normalnych odpowada charakterystyce histogramów.

Dodatowo można zauważyć, iż spółka LPP cechowała się większą stabilnością na giełdzie. Świadczy o tym mniejsze odchylenie standardowe zmian procentowych niż to obecne w danych dla spółki PLAY.

## Zadanie 2

Sekcja ta definiuje funkcje odpowiedzilne za odpowiednie wczytanie danych i ich przygotowanie. 

* load_data - wczytuje dane z pliku do tabeli (data frame-u)
* prepare data:
  + wydzielenie przedział czasu, którego dotyczny zadanie (październik 2019) 
  + dodanie kolumny *id* - ma to na celu dodanie możliości odtworzenia pierwotnej kolejności danych (transakcji)

### Przygotowanie danych

```{r}
load_data <- function(path) {
  return(read.table(path, sep = ",", header = TRUE))
}

prepare_data <- function(df) {
  # Filter data to suit assagnment details (transactions in October 2019)
  df <- df[df$date >= 191001 & df$date <= 191031,]
  
  # Add id column
  data <- tibble::rowid_to_column(df, "id")

  return (data)
}
```


### Na podstawie danych z pazdziernika 2019 (z pliku zad2csv new.zip) dotyczacych zadanej spółki:

### (a) Zilustruj jak wolumen transakcji rozkłada sie pomiedzy 3 fazy notowan: otwarcie, notowania ciagłe, zamkniecie z dogrywka.

* extract_opening_transactions - wydziela transakcje należące do grupy otwarcia
  + wyznacznie pierwyszych transkcji o godzinie 9 dla każdego dnia
  + wyszukanie transakcji, które mają tę samą cenę co pierwsza transakcja z godziny 9
* extract_continous_transactions - wydziela transakcje należące do grupy notowań ciągłych
  + wyznacznie tych transakcji, które nie należą do fazy otwarcia i wystąpiły do 16:51
* extract_closing_transactions - wydziela transakcje należące do grupy notowań zamknięcia z dogrywką
  + wyznacznie tych transakcji, które wystąpiły po 16:59
* extract_transaction_groups - wywołuje poprzednie funkcje i agreguje wyniki w listę

```{r}
extract_opening_transactions <- function(df) {
  # Select first opening transaction for each day
  first_opening_transactions <- df[df$time == 90000,] %>% group_by(date) %>% slice(1)

  # Select opening transaction
  opening_transactions <- data.frame(first_opening_transactions)

  # Select related transactions for each of first opening transactions
  for (i in 1:nrow(first_opening_transactions)) {
    result <- data.frame(df[df$date == first_opening_transactions$date[i] 
              & df$time == first_opening_transactions$time[i] 
              & df$price == first_opening_transactions$price[i] 
              & df$id != first_opening_transactions$id[i],]) # Skip transactions from first_opening_transactions

    opening_transactions <- rbind(opening_transactions, result)
  }

  return(opening_transactions[order(opening_transactions$id),])
}

extract_continous_transactions <- function(df, opening_transactions) {
  return(df[df$time <= 165100 & !(df$id %in% opening_transactions$id),])
}

extract_closing_transactions <- function(df, opening_transactions) {
  return(df[df$time >= 165900,])
}

extract_transaction_groups <- function(df) {
  opening_transactions <- extract_opening_transactions(df)
  continous_transactions <- extract_continous_transactions(df, opening_transactions)
  closing_transactions <- extract_closing_transactions(df)

  return(list(opening=opening_transactions, continous=continous_transactions, closing=closing_transactions))
}
```

* sum_volumes_by_day - sumuję wolumen dla każdego dnia

```{r}
sum_volumes_by_day <- function(dataset) {
  return(dataset %>% group_by(date) %>% summarise(volume = sum(volume)))
}

```

#### Wydzielenie grup

```{r}
transactions <- load_data("./data/p1csv_new/PGE.csv") %>% prepare_data %>% extract_transaction_groups

opening <- data.frame(group="opening", sum_volumes_by_day(transactions$opening) %>% select(volume))
continous <- data.frame(group="continous", sum_volumes_by_day(transactions$continous) %>% select(volume))
closing <- data.frame(group="closing", sum_volumes_by_day(transactions$closing) %>% select(volume))
```

#### Rozkład wolumenu transakcji fazy otwarcia (wykres pudełkowy)
```{r}
ggplot(opening, aes(x=volume)) + 
geom_boxplot() + 
theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
labs(title = "Rozkład wolumenu transakcji fazy otwarcia", y="", x="Suma wolumentów")
```

#### Rozkład wolumenu transakcji fazy notowań ciagłego (wykres pudełkowy)
```{r}
ggplot(continous, aes(x=volume)) + 
geom_boxplot() + 
theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
labs(title = "Rozkład wolumenu transakcji fazy notowań ciagłego", y="", x="Suma wolumentów")
```

#### Rozkład wolumenu transakcji fazy zamknięcia (wykres pudełkowy)
```{r}
ggplot(closing, aes(x=volume)) + 
geom_boxplot() + 
theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) +
labs(title = "Rozkład wolumenu transakcji fazy zamknięcia", y="", x="Suma wolumentów")
```

#### Porównanie wyżej wymienionych  rozkładów (wykres pudełkowy)
```{r}
ggplot(rbind(opening, continous, closing), aes(x=group, y=volume, fill=group)) + 
geom_boxplot() + 
labs(title = "Porównanie wyżej wymienionych  rozkładów", x="Grupy (fazy)", y="Suma wolumentów", color="Grupy (fazy)")
```

#### Komentarz
Jak widać na przedstawionym porównaniu grupa notowań ciągłych (continous) zawiera największą sume wolumenów. Nie powinno to jednak dziwić, ponieważ grupa ta zawiera najwięcej transakcji. 
Co jednak może dziwić to wartości odstające w grupie zamknięcia (closing). Jedena z ów wartości odstających przewyższa wartości z grupy notowań ciągłych. 

### (b) zilustruj jak wolumen transakcji rozkłada sie w czasie notowan ciagłych
W celu ilustarcji rozkładu wolumentu transakcji w czasie, grupa notowań ciągłych została podzielnoa na godziny a następnie zliczona została suma wolumentów w każdej godzinie.

* extract_hours - dodaje kolumne *hour* z pełną godziną na podstawie kolumny *time*

```{r}
extract_hours <- function(df) {
  for (i in 1:nrow(df)) {
     df$hour[i] = df$time[i] %/% 10000
  }
  return(df)
}
```

* sum_volumes_by_hour - sumuję wartości wolumentów transakcji dla każdej godziny

```{r}
sum_volumes_by_hour <- function(df) {
  return(df %>% group_by(hour) %>% summarise(volume = sum(volume)))
}
```

#### Rozkład wolumanu transakcji w czasie
Rozkład wolumenu transkacji w czasie został zilustrowany przy pomocy histogramu

```{r}
volumes_sum_by_hour <- transactions$continous %>% extract_hours %>% sum_volumes_by_hour
g <- ggplot(volumes_sum_by_hour, aes(x=hour, y=volume))
g + geom_col() + labs(title = "Histogram rozkładu sumy wolumenów dla każdej godziny", x="Godzina", y="Suma wolumentów")
```

#### Komentarz
Na podstawie wygenerowanego rozkładu wolumenu transakcji w czasie notowań ciągłych można stwierdzić, po lekkim zwięszeniu sumy wolumentów w godzinnach porannych (9-10), 
następuje lekki spadek i stabilizacja do ok. godz. 15. W okolicach godz. 15 notowany jest duży wzrost sumy wolumenów po czym następuję lekki spadek do godz. 16.

### (c) Wyznacz dzień i jego 2-godzinny przedział czasu rozpoczynający się o pełnej godzinie między 10:00 a 14:00 włącznie, w którym jest najmniej sekund, w których przeprowadzane były transakcje na akcjach danej spółki.

```{r}
count_used_secs_by_hour <- function(df) {
  return(df %>% group_by(date, hour) %>% summarise(n_distinct(time)))
}

transactions_by_hour <- load_data("./data/p1csv_new/PGE.csv") %>% 
                        prepare_data %>% 
                        filter(time >= 100000, time < 160000) %>% 
                        extract_hours %>% 
                        count_used_secs_by_hour

names(transactions_by_hour)[3] <- "count"
```

```{r}
extract_2h_time_frame_min_secs <- function(df) {
  min_secs = 99999999
  start_hour = 0
  date = 0
  for (i in 1:(nrow(df)-1)) {
    count_for_2h <- df$count[[i]] + df$count[[i+1]]
    if(count_for_2h < min_secs){
      date <- df$date[i]
      start_hour <- df$hour[i]
      min_secs <- count_for_2h
    }
  }
  
  return(list(date=date, start_hour=start_hour, min_secs=min_secs))
}

#extract_all_distinct_transactions_in_2h <- function(list_res) {
min_secs_time_frame <- extract_2h_time_frame_min_secs(transactions_by_hour)
min_secs_date <- min_secs_time_frame$date
min_secs_start_time <- min_secs_time_frame$start_hour * 10000
min_secs_finish_time <- min_secs_start_time + 20000 # plus 2 hours
min_secs_data_df <- load_data("./data/p1csv_new/PGE.csv") %>% 
                    prepare_data %>% 
                    filter(time >= min_secs_start_time, time <= min_secs_finish_time, date==min_secs_date) %>% 
                    distinct(time, .keep_all = TRUE)
```


#### (i). W każdej kolejnej minucie rozważanego przedziału wyznacz liczbę sekund, w których przeprowadzane były transakcje (otrzyma się w ten sposób 120 liczb z przedziału [0, 60]).

```{r}
extract_minutes_start_from <- function(start_time) {
  times <- c(as.integer(start_time / 100)) # 2 - start time
  actual_minute <- times[1]
  for(i in 1:120) {
    actual_minute <- actual_minute + 1 # plus 1 min
    if(str_detect(actual_minute, "60$")) { # next hour
      actual_minute <- actual_minute + 40
    }
    times <- c(times, actual_minute)
  }

  return(times)
}

count_used_secs_per_min <- function(start_time, df) {
  times <- extract_minutes_start_from(start_time)
  counts <- c() 
  for(i in 1:length(times)) {
    time <- times[i]
    pattern <- paste("^", time, sep = "")
    num_used_secs <- df %>% filter(str_detect(time, pattern)) %>% nrow
    counts <- c(counts, num_used_secs)
  }
  
  return(data.frame(times, counts))
}

```

```{r}
df_count_per_minute <- count_used_secs_per_min(min_secs_start_time, min_secs_data_df)
df_count_per_minute$minute <- seq.int(0:120)
```


```{r}
ggplot(data = df_count_per_minute) +
  geom_bar(aes(x = minute,
               y = counts),
           stat="identity") +
  scale_x_continuous(breaks=seq(0,120,5)) +
  scale_y_continuous(breaks=seq(min(df_count_per_minute$counts),
                                max(df_count_per_minute$counts),
                                 1)) +
  labs(x = 'Minuta',
       y = 'Ilosc transakcyj',
       title = 'Liczba uzytych sekund na transakcje w ciągu minuty') +
  theme_bw()
```


#### (ii). Zamodeluj ww. liczby za pomocą rozkładu Poissona.

```{r}

lambda = mean(df_count_per_minute$counts)
num_transactions <- 0:10
density <- dpois(x = num_transactions, lambda)
prob <- ppois(q = num_transactions, lambda, lower.tail = TRUE)
df <- data.frame(num_transactions, density, prob)
ggplot(df, aes(x = num_transactions, y = density)) +
  scale_x_continuous(breaks=seq(0,10,1)) +
  geom_text(aes(label = round(density,2)), size=3, vjust=-1) +
  labs(title = " Rozkład prawdopodobieństwa oraz Dystrubuanta",
       x = "Liczba transakcji na minute",
       y = "") +
  geom_line(data = df, aes(x = num_transactions, y = prob, color="Dystrubuanta")) +
  geom_line(data = df, aes(x = num_transactions, y = density, color="Rozkład Poissona")) +
  geom_point(aes(x = num_transactions, y = density, ), size=2 )
  #geom_segment(aes(x=num_transactions, y = prob, xend=num_transactions+1, yend=prob), size=0.7)
```

#### (iii). porównaj rozkład modelowy z danymi.
```{r}
plot_comparison <- function(data, dnorm_params, col="darkmagenta") {
  hist <- hist(data, main="Histogram rozkłądu ilości tranzakcji w minutę", xlab="Liczba uzytych sekund w minute", ylab="Liczność", col=col, ylim=c(0,30), breaks=50) 
  xfit <- num_transactions
  yfit <- density
  yfit <- yfit * diff(hist$mids[1:2]) * length(data) 
  lines(xfit, yfit, col = "red", lwd = 2)
}

plot_comparison(df_count_per_minute$counts)
```
    